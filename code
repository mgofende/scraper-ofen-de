import requests
from bs4 import BeautifulSoup
import pandas as pd
import re

# -----------------------------
# Schritt 1: ofen.de Produktinfos
# -----------------------------
def scrape_ofen(url, artikelnummer=None, ean=None):
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, "html.parser")
    
    # Modell / Produktname
    modell_tag = soup.find('h1', class_='product--title') or soup.find('h1', class_='product-header-title')
    modell = modell_tag.text.strip() if modell_tag else None
    
    # Artikelnummer
    if not artikelnummer:
        all_text = soup.get_text()
        match = re.search(r'Artikel-?Nr\.?:\s*(\d+)', all_text)
        artikelnummer = match.group(1) if match else None
    
    # Preis aktuell (rot)
    preis_tag = soup.find('span', class_='price--content') or soup.find('div', class_='price--current')
    preis = preis_tag.text.strip() if preis_tag else None
    
    # UVP
    uvp_tag = soup.find('span', class_='price--line-through') or soup.find('span', class_='price-old')
    uvp = uvp_tag.text.strip() if uvp_tag else None
    
    # Lieferzeit
    lieferzeit_tag = soup.find(text=re.compile(r"Lieferzeit"))  # einfacher Ansatz
    lieferzeit = lieferzeit_tag.strip() if lieferzeit_tag else None
    
    # EAN
    if not ean:
        all_text = soup.get_text()
        ean_match = re.search(r'\b(\d{13})\b', all_text)
        ean = ean_match.group(1) if ean_match else None
    
    return {
        "Modell": modell,
        "Artikelnummer": artikelnummer,
        "EAN": ean,
        "Preis_Ofen": preis,
        "UVP_Ofen": uvp,
        "Lieferzeit_Ofen": lieferzeit
    }

# -----------------------------
# Schritt 2: Shops durchsuchen
# -----------------------------
def scrape_feuerdepot(product):
    results = {}
    query = product['Modell'].replace(" ", "+")
    url = f"https://www.feuerdepot.de/suche/?search={query}"
    
    try:
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(r.text, "html.parser")
        
        # Beispiel: Erstes Suchergebnis
        first_item = soup.find('div', class_='product-item')  # ggf. anpassen
        if first_item:
            prod_url = first_item.find('a')['href']
            name = first_item.find('a').text.strip()
            # UVP / Preis / Lieferzeit m√ºssten auf Produktseite
            r2 = requests.get(prod_url, headers={"User-Agent": "Mozilla/5.0"})
            soup2 = BeautifulSoup(r2.text, "html.parser")
            uvp_tag = soup2.find('span', class_='price--line-through')
            uvp = uvp_tag.text.strip() if uvp_tag else None
            preis_tag = soup2.find('span', class_='price--content')
            preis = preis_tag.text.strip() if preis_tag else None
            liefer_tag = soup2.find(text=re.compile(r'Lieferzeit'))
            lieferzeit = liefer_tag.strip() if liefer_tag else None
            
            results = {
                "Shop": "Feuerdepot",
                "URL": prod_url,
                "Name": name,
                "UVP": uvp,
                "Preis": preis,
                "Lieferzeit": lieferzeit
            }
    except:
        results = {"Shop": "Feuerdepot", "URL": None, "Name": None, "UVP": None, "Preis": None, "Lieferzeit": None}
    return results

def scrape_kamdi(product):
    results = {}
    query = product['Modell'].replace(" ", "-").lower()
    url = f"https://www.kamdi24.de/suche/?q={query}"
    
    try:
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(r.text, "html.parser")
        
        first_item = soup.find('div', class_='product-item')  # anpassen je nach Shop
        if first_item:
            prod_url = first_item.find('a')['href']
            name = first_item.find('a').text.strip()
            r2 = requests.get(prod_url, headers={"User-Agent": "Mozilla/5.0"})
            soup2 = BeautifulSoup(r2.text, "html.parser")
            uvp_tag = soup2.find('span', class_='old-price')
            uvp = uvp_tag.text.strip() if uvp_tag else None
            preis_tag = soup2.find('span', class_='price')
            preis = preis_tag.text.strip() if preis_tag else None
            liefer_tag = soup2.find(text=re.compile(r'Lieferzeit'))
            lieferzeit = liefer_tag.strip() if liefer_tag else None
            
            results = {
                "Shop": "Kamdi24",
                "URL": prod_url,
                "Name": name,
                "UVP": uvp,
                "Preis": preis,
                "Lieferzeit": lieferzeit
            }
    except:
        results = {"Shop": "Kamdi24", "URL": None, "Name": None, "UVP": None, "Preis": None, "Lieferzeit": None}
    return results

def scrape_feuerfuchs(product):
    results = {}
    query = product['Modell'].replace(" ", "+")
    url = f"https://www.feuer-fuchs.de/suche/?search={query}"
    
    try:
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(r.text, "html.parser")
        
        first_item = soup.find('div', class_='product-item')  # anpassen je nach Shop
        if first_item:
            prod_url = first_item.find('a')['href']
            name = first_item.find('a').text.strip()
            r2 = requests.get(prod_url, headers={"User-Agent": "Mozilla/5.0"})
            soup2 = BeautifulSoup(r2.text, "html.parser")
            uvp_tag = soup2.find('span', class_='price--line-through')
            uvp = uvp_tag.text.strip() if uvp_tag else None
            preis_tag = soup2.find('span', class_='price--content')
            preis = preis_tag.text.strip() if preis_tag else None
            liefer_tag = soup2.find(text=re.compile(r'Lieferzeit'))
            lieferzeit = liefer_tag.strip() if liefer_tag else None
            
            results = {
                "Shop": "Feuer-Fuchs",
                "URL": prod_url,
                "Name": name,
                "UVP": uvp,
                "Preis": preis,
                "Lieferzeit": lieferzeit
            }
    except:
        results = {"Shop": "Feuer-Fuchs", "URL": None, "Name": None, "UVP": None, "Preis": None, "Lieferzeit": None}
    return results

# -----------------------------
# Main
# -----------------------------
if __name__ == "__main__":
    url = input("ofen.de URL eingeben: ")
    artikelnummer = input("Optional: Hersteller Artikelnummer eingeben: ")
    ean = input("Optional: EAN eingeben: ")
    
    product = scrape_ofen(url, artikelnummer=artikelnummer if artikelnummer else None, ean=ean if ean else None)
    print("Produktdaten von ofen.de:")
    print(product)
    
    results = []
    results.append(scrape_feuerdepot(product))
    results.append(scrape_kamdi(product))
    results.append(scrape_feuerfuchs(product))
    
    df = pd.DataFrame(results)
    print("\nPreisvergleich Ergebnisse:")
    print(df)
    
    df.to_csv("preisvergleich.csv", index=False)
    print("\nErgebnisse in preisvergleich.csv gespeichert.")
